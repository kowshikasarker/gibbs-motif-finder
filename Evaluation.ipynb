{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Evaluation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "brb_1_k37OIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from openpyxl import load_workbook"
      ],
      "metadata": {
        "id": "wH-Q9bwg8QcO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Relative Entropy"
      ],
      "metadata": {
        "id": "oIqZmiguv0jh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def relativeEntropy(matrix1, matrix2, size):\n",
        "  val1 = np.array(matrix1)\n",
        "  val2 = np.array(matrix2)\n",
        "  sum = 0\n",
        "  for x in range(0,size):\n",
        "    for y in range(0,4):\n",
        "      valComp = val1[x][y]* np.log(val1[x][y]/val2[x][y])\n",
        "      sum = sum + valComp\n",
        "  return sum"
      ],
      "metadata": {
        "id": "xe5QBfKO8vDD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#base, ref matrix\n",
        "def calc_relative_entropy(path1, path2):\n",
        "  matrix1 = []\n",
        "\n",
        "  fileMatrix1 = open(path1, 'r')\n",
        "  for line in fileMatrix1.readlines():\n",
        "      if line.startswith('>') or line.startswith('<'):\n",
        "        continue\n",
        "      else:\n",
        "        matrix1.append(line.strip().split(' ')[0:4])\n",
        "  fileMatrix1.close()\n",
        "\n",
        "  matrix2 = []\n",
        "\n",
        "  fileMatrix2 = open(path2, 'r')\n",
        "  for line in fileMatrix2.readlines():\n",
        "      if line.startswith('>') or line.startswith('<'):\n",
        "        continue\n",
        "      else:\n",
        "        matrix2.append(line.strip().split(' ')[0:4])\n",
        "\n",
        "  fileMatrix2.close()\n",
        "\n",
        "  valueMatrix1 = ( [list( map(float,i) ) for i in matrix1] )\n",
        "  valueMatrix2 = ( [list( map(float,i) ) for i in matrix2] )\n",
        "  \n",
        "  #sum of rows should all be the same unless something is really wrong.\n",
        "  valueMatrix1Sum = sum(valueMatrix1[0])\n",
        "  valueMatrix2Sum = sum(valueMatrix2[0])\n",
        "\n",
        "  valueMatrix1ToCompute = [[x/valueMatrix1Sum for x in lst] for lst in valueMatrix1]\n",
        "  valueMatrix2ToCompute = [[x/valueMatrix2Sum for x in lst] for lst in valueMatrix2]\n",
        "\n",
        "  #remove zeros, piazza for epsilon, avoid div by 0\n",
        "  valueMatrix1ToComputeNoZero = [[value + 0.0001 for value in row] for row in valueMatrix1ToCompute]\n",
        "  valueMatrix2ToComputeNoZero = [[value + 0.0001 for value in row] for row in valueMatrix2ToCompute]\n",
        "  \n",
        "  valueMatrix1Sum = sum(valueMatrix1ToComputeNoZero[0])\n",
        "  valueMatrix2Sum = sum(valueMatrix2ToComputeNoZero[0])\n",
        "\n",
        "  valueMatrix1ToComputeNoZero = [[x/valueMatrix1Sum for x in lst] for lst in valueMatrix1ToComputeNoZero]\n",
        "  valueMatrix2ToComputeNoZero = [[x/valueMatrix2Sum for x in lst] for lst in valueMatrix2ToComputeNoZero]\n",
        "\n",
        "  res =relativeEntropy(valueMatrix1ToComputeNoZero, valueMatrix2ToComputeNoZero, len(valueMatrix1ToComputeNoZero))\n",
        "  return res"
      ],
      "metadata": {
        "id": "lkZfwixpHFcP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''result_dir = '/content/drive/My Drive/CS466/Project/Result/Dataset-1.2'\n",
        "for dataset_no in range(1, 71):\n",
        "  data_dir = result_dir + '/' + str(dataset_no)\n",
        "  path1 = data_dir + '/predictedmotif.txt' \n",
        "  path2 = data_dir + '/motif.txt'\n",
        "  entropy = calc_relative_entropy(path1, path2)\n",
        "  print('dataset_no', dataset_no, 'entropy', entropy)'''"
      ],
      "metadata": {
        "id": "uCdOQIXRM3ow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Site Overlap"
      ],
      "metadata": {
        "id": "STYvAEqxv2gP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_site_overlap(path1, path2):\n",
        "  file1 = open(path1, 'r')\n",
        "  pos1 = file1.readline().strip().split(',')\n",
        "  pos1 = [int(pos) for pos in pos1]\n",
        "\n",
        "  file2 = open(path2, 'r')\n",
        "  pos2 = file2.readline().strip().split(',')\n",
        "  pos2 = [int(pos) for pos in pos2]\n",
        "\n",
        "  #print(pos1)\n",
        "  #print(pos2)\n",
        "\n",
        "  if(len(pos1) != len(pos2)):\n",
        "    print('ERROR! Size mismatch!!')\n",
        "    return -1\n",
        "  \n",
        "  correct = 0\n",
        "  total = len(pos1)\n",
        "\n",
        "  for i in range(total):\n",
        "    if(pos1[i] == pos2[i]):\n",
        "      correct += 1\n",
        "\n",
        "  correct = (correct / total) * 100\n",
        "\n",
        "  return correct\n"
      ],
      "metadata": {
        "id": "y_eIJ1F1T-qp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''result_dir = '/content/drive/My Drive/CS466/Project/Result/Dataset-1.5'\n",
        "for dataset_no in range(1, 71):\n",
        "  data_dir = result_dir + '/' + str(dataset_no)\n",
        "  path1 = data_dir + '/predictedsites.txt' \n",
        "  path2 = data_dir + '/sites.txt'\n",
        "  overlap = calc_site_overlap(path1, path2)\n",
        "  print('dataset_no', dataset_no, 'overlap', overlap)'''"
      ],
      "metadata": {
        "id": "TEyP6OsCVBAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IC & Running Time"
      ],
      "metadata": {
        "id": "Y5pY8we8v8Um"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_info_content_runtime(path1, path2):\n",
        "  file1 = open(path1, 'r')\n",
        "  ic = float(file1.readline().strip())\n",
        "  file1.close()\n",
        "\n",
        "  file2 = open(path2, 'r')\n",
        "  rt = float(file2.readline().strip())\n",
        "  file2.close()\n",
        "\n",
        "  return ic, rt\n"
      ],
      "metadata": {
        "id": "L880WynNWWNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''result_dir = '/content/drive/My Drive/CS466/Project/Result/Dataset-1.5'\n",
        "for dataset_no in range(1, 71):\n",
        "  data_dir = result_dir + '/' + str(dataset_no)\n",
        "  path = data_dir + '/summary.txt' \n",
        "  ic, rt = calc_info_content_runtime(path)\n",
        "  print('dataset_no', dataset_no, 'ic', ic, 'rt', rt)'''"
      ],
      "metadata": {
        "id": "FvHW8dJ-YGcH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Evaluation"
      ],
      "metadata": {
        "id": "hxCDqooiYdH8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(dataset_name):\n",
        "  print('Evaluating', dataset_name)\n",
        "  \n",
        "  result_dir = '/content/drive/My Drive/CS466/Project/Result/' + dataset_name\n",
        "\n",
        "  metrics = []\n",
        "\n",
        "  for dataset_no in range(1, 71):\n",
        "    data_dir = result_dir + '/' + str(dataset_no)\n",
        "\n",
        "    motif_path1 = data_dir + '/predictedmotif.txt' \n",
        "    motif_path2 = data_dir + '/motif.txt'\n",
        "    entropy = calc_relative_entropy(motif_path1, motif_path2)\n",
        "    \n",
        "    site_path1 = data_dir + '/predictedsites.txt' \n",
        "    site_path2 = data_dir + '/sites.txt'\n",
        "    overlap = calc_site_overlap(site_path1, site_path2)\n",
        "    \n",
        "    ic_path = data_dir + '/ic.txt' \n",
        "    rt_path = data_dir + '/runtime.txt' \n",
        "    ic, rt = calc_info_content_runtime(ic_path, rt_path)\n",
        "\n",
        "    metrics.append([dataset_no, entropy, overlap, ic, rt])\n",
        "\n",
        "    print('dataset_no', dataset_no, 'entropy', entropy, 'overlap', overlap, 'ic', ic, 'rt', rt)\n",
        "\n",
        "\n",
        "  book = load_workbook(result_dir + '/' + dataset_name + '.xlsx')\n",
        "  writer = pd.ExcelWriter(result_dir + '/' + dataset_name + '.xlsx', engine = 'openpyxl')\n",
        "  writer.book = book\n",
        "\n",
        "  metric_df = pd.DataFrame(data=metrics, columns=['dataset_no', 'entropy', 'overlap', 'info_cont', 'runtime'])\n",
        "\n",
        "  metric_df.to_excel(writer, sheet_name = 'Metrics', index=False)\n",
        "  writer.save()\n",
        "  writer.close()"
      ],
      "metadata": {
        "id": "-s_07CJ8Yeau"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dataset_names = ['Dataset-1.1', 'Dataset-1.2', 'Dataset-1.3', 'Dataset-1.5']\n",
        "dataset_names = ['Dataset-2.4']\n",
        "for dataset_name in dataset_names:\n",
        "  evaluate(dataset_name)"
      ],
      "metadata": {
        "id": "SitmccVabFsL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#IC Correlation"
      ],
      "metadata": {
        "id": "ZRAt_ftRv4VJ"
      }
    }
  ]
}